---
title: "Indexing techproducts"
author: "Cath Riddoch"
format:
  html:
    df-print: paged
---

## Starting the server

\``/bin/solr start -e cloud`\`

and started two nodes

![](Screenshot%202023-02-28%20at%2010.46.17%20am.png)

## Initial setup of Solarium

```{r}
#| warning: false
#install.packages("solrium")
library(solrium) 

# load tidyverse
library(tidyverse)
```

```{r}
# Create a Solr client
solr_client <- SolrClient$new()
```

```{r}
#create the collection
 if (!solr_client$collection_exists("techproducts")) {
	 solr_client$collection_create(name = "techproducts",
                                  maxShardsPerNode = 2,
                                  numShards = 2,
                                  replicationFactor = 2,
                                  collection.configName = "techproducts"
                                )
 }

```

![](images/Screenshot%202023-03-07%20at%201.50.52%20pm.png)

This creates an empty collection. Search for everything carried out to check.

```{r}
#check collection exists and is empty
solr_client$search(name = "techproducts", params = list(q = "*:*"))
```

```{r}
# function to index all files in a folder
uploadAll<- function(path, collection){
  jsonFiles <- list.files(path = path,
                          pattern = "*.json*",
                          full.names = TRUE,
                          recursive = FALSE
                          )
  jsonUpload <-function(file) (solr_client$update_json(file, collection))
  map(jsonFiles, jsonUpload)

  xmlFiles <- list.files(path = path,
                         pattern = "*.xml",
                         full.names = TRUE,
                         recursive = FALSE
                         )
  xmlUpload <-function(file) (solr_client$update_xml(file, collection))
  map(xmlFiles, xmlUpload)

  csvFiles <- list.files(path = path,
                       pattern = "*.csv",
                       full.names = TRUE,
                       recursive = FALSE
                       )
  csvUpload <-function(file) (solr_client$update_csv(file, collection))
  map(csvFiles, csvUpload)
}

```

```{r}
# runs the upload function
# note does not find or index .sh files
uploadAll("solr-files/example/exampledocs", "techproducts")
```

```{r}
# searching on a single term
solr_client$search(name = "techproducts", params = list(q = "foundation"))
```

```{r}
# returning the number of records found
genSearch <- solr_client$search(name = "techproducts", params = list(q = "electronics"))
attr(genSearch, "numFound")

```

```{r}
# searching in a specific category
searchCat <- solr_client$search(name = "techproducts", params = list(q = "cat:electronics"))
searchCat
```

```{r}
attr(searchCat, "numFound")
```

```{r}
compSearch <- solr_client$search(name = "techproducts", params = list(q = "+electronics +music"))
attr(compSearch, "numFound")
```

Find all electronics but don't contain term "music"

```{r}
mixSearch <- solr_client$search(name = "techproducts", params = list(q = "+electronics -music"))
attr(mixSearch, "numFound")

```

```{r}
# phrase search
phraseSearch <- solr_client$search(name = "techproducts", params = list(q = "CAS+latency"))
attr(phraseSearch, "numFound")

```

`solr_all()` differs from `solr_search()` in that it allows specifying facets, mlt, groups, stats, etc, and returns all of those. It defaults to `parsetype = "list"` and `wt="json"`, whereas `solr_search()` defaults to `parsetype = "df"` and `wt="csv"`. `solr_all()` returns by default a list, whereas `solr_search()` by default returns a data.frame.
